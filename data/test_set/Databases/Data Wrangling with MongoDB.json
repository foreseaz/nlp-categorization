{"selfpaced": true, "topic_name": ["Databases"], "description": "\n\n                    \n                    \n                    In this course, we will explore how to wrangle data from diverse sources and shape it to enable data-driven applications. Some data scientists spend the bulk of their time doing this!\n\nStudents will learn how to gather and extract data from widely used data formats. They will learn how to assess the quality of data and explore best practices for data cleaning. We will also introduce students to MongoDB, covering the essentials of storing data and the MongoDB query language together with exploratory analysis using the MongoDB aggregation framework.\n\nThis is a great course for those interested in entry-level data science positions as well as current business/data analysts looking to add big data to their repertoire, and managers working with data professionals or looking to leverage big data.\n\nThis course is also a part of our Data Analyst Nanodegree.Why Take This Course?At the end of the class, students should be able to:\n\n*   Programmatically extract data stored in common formats such as csv, Microsoft Excel, JSON, XML and scrape web sites to parse data from HTML.\n*   Audit data for quality (validity, accuracy, completeness, consistency, and uniformity) and critically assess options for cleaning data in different contexts. \n*   Store, retrieve, and analyze data using MongoDB.\n\n\nThis course concludes with a final project where students incorporate what they have learned to address a real-world data analysis problem.\n\n                                            Syllabus\n                        ### Lesson 1: Data Extraction Fundamentals\n\n- Assessing the Quality of Data\n- Intro to Tabular Formats\n- Parsing CSV\n- Parsing XLS with XLRD\n- Intro to JSON\n- Using Web APIs\n\n### Lesson 2: Data in More Complex Formats\n\n- Intro to XML\n- XML Design Principles\n- Parsing XML\n- Web Scraping\n- Parsing HTML\n\n\n### Lesson 3: Data Quality \n\n- What is Data Cleaning?\n- Sources of Dirty Data\n- Measuring Data Quality\n- A Blueprint for Cleaning\n- Auditing Validity \n- Auditing Accuracy\n- Auditing Completeness\n- Auditing Consistency\n- Auditing Uniformity\n\n### Lesson 4: Working with MongoDB\n\n- Data Modelling in MongoDB\n- Introduction to PyMongo\n- Field Queries\n- Projection Queries\n- Getting Data into MongoDB\n- Using mongoimport\n- Operators like $gt, $lt, $exists, $regex\n- Querying Arrays and using $in and $all Operators\n- Changing entries: $update, $set, $unset\n\n### Lesson 5: Analyzing Data\n\n- Examples of Aggregation Framework \n- The Aggregation Pipeline\n- Aggregation Operators: $match, $project, $unwind, $group\n- Multiple Stages Using a Given Operator\n\n### Lesson 6: Case Study - OpenStreetMap Data\n\n- Using iterative parsing for large datafiles\n- Open Street Map XML Overview\n- Exercises around OpenStreetMap data\n- Final Project Instructions\n                                    ", "end_date": "2014-04-23T00:00:00Z", "title": "Data Wrangling with MongoDB", "price": 0, "instructors": "Shannon Bradshaw", "institution_name": ["MongoDB University"], "commitment": "6 hours", "subject_name": ["Programming"], "course_url": "https://www.udacity.com/course/data-wrangling-with-mongodb--ud032?utm_medium=referral&utm_campaign=api", "duration": "8 weeks", "language_name": ["English"], "provider_name": ["Udacity"], "start_date": "2014-02-26T00:00:00Z"}
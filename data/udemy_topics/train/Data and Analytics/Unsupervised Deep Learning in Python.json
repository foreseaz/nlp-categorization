{
    "selfpaced": true, 
    "topic_name": [
        "Business"
    ], 
    "description": "<p>This course is the next logical step in my <strong class=\"redactor-inline-converted\">deep learning, data science,</strong> and <strong class=\"redactor-inline-converted\">machine learning</strong> series. I’ve done a lot of courses about deep learning, and I just released a course about <strong class=\"redactor-inline-converted\">unsupervised learning</strong>, where I talked about <strong class=\"redactor-inline-converted\">clustering</strong> and <strong class=\"redactor-inline-converted\">density estimation</strong>. So what do you get when you put these 2 together? Unsupervised deep learning!</p>\n\n<p>In these course we’ll start with some very basic stuff - <strong class=\"redactor-inline-converted\">principal components analysis (PCA)</strong>, and a popular nonlinear dimensionality reduction technique known as <strong class=\"redactor-inline-converted\">t-SNE (t-distributed stochastic neighbor embedding)</strong>.</p>\n\n\n\n\n\n\n\n<p>Next, we’ll look at a special type of unsupervised neural network called the <strong class=\"redactor-inline-converted\">autoencoder</strong>. After describing how an autoencoder works, I’ll show you how you can link a bunch of them together to form a deep stack of autoencoders, that leads to better performance of a supervised<strong class=\"redactor-inline-converted\"> deep neural network</strong>. Autoencoders are like a non-linear form of PCA.</p>\n\n\n\n\n\n\n\n<p>Last, we’ll look at <strong class=\"redactor-inline-converted\">restricted Boltzmann machines (RBMs)</strong>. These are yet another popular unsupervised neural network, that you can use in the same way as autoencoders to <strong class=\"redactor-inline-converted\">pretrain</strong> your supervised deep neural network. I’ll show you an interesting way of training restricted Boltzmann machines, known as <strong class=\"redactor-inline-converted\">Gibbs sampling</strong>, a special case of <strong class=\"redactor-inline-converted\">Markov Chain Monte Carlo,</strong> and I’ll demonstrate how even though this method is only a rough approximation, it still ends up reducing other cost functions, such as the one used for autoencoders. This method is also known as <strong class=\"redactor-inline-converted\">Contrastive Divergence</strong> or <strong class=\"redactor-inline-converted\">CD-k</strong>. As in physical systems, we define a concept called <strong class=\"redactor-inline-converted\">free energy</strong> and attempt to minimize this quantity.</p>\n\n\n\n\n\n<p>Finally, we’ll bring all these concepts together and I’ll show you visually what happens when you use PCA and t-SNE on the features that the autoencoders and RBMs have learned, and we’ll see that even without labels the results suggest that a pattern has been found.</p>\n\n\n\n<p>All the materials used in this course are FREE. Since this course is the 4th in the deep learning series, I will assume you already know calculus, linear algebra, and <strong>Python</strong> coding. You'll want to install <strong class=\"redactor-inline-converted\">Numpy</strong> and <strong class=\"redactor-inline-converted\">Theano</strong> for this course. These are essential items in your <strong>data analytics</strong> toolbox.</p>\n\n\n\n<p>If you are interested in deep learning and you want to learn about modern deep learning developments beyond just plain <strong class=\"redactor-inline-converted\">backpropagation</strong>, including using unsupervised neural networks to interpret what features can be automatically and hierarchically learned in a deep learning system, this course is for you.</p><p><br></p><p>NOTES:</p><p>All the code for this course can be downloaded from my github: /lazyprogrammer/machine_learning_examples</p>\n\n<p>In the directory: unsupervised_class2</p>\n\n<p>Make sure you always \"git pull\" so you have the latest version!</p>\n\n<p>HARD PREREQUISITES / KNOWLEDGE YOU ARE ASSUMED TO HAVE:</p>\n\n<ul><li>calculus</li><li>linear algebra</li><li>probability</li><li>Python coding: if/else, loops, lists, dicts, sets</li><li>Numpy coding: matrix and vector operations, loading a CSV file</li></ul><p><br></p>", 
    "end_date": null, 
    "title": "Unsupervised Deep Learning in Python", 
    "price": "50.00", 
    "instructors": "Justin C", 
    "commitment": "2.5 hours", 
    "cover_url": "https://udemy-images.udemy.com/course/750x422/846480_d909.jpg", 
    "course_url": "https://www.udemy.com/unsupervised-deep-learning-in-python/", 
    "currency": "USD", 
    "subject_name": [
        "Data & Analytics"
    ], 
    "duration": null, 
    "language_name": [
        "English"
    ], 
    "provider_name": [
        "udemy"
    ], 
    "start_date": "2016-05-11T20:56:27Z"
}
{
    "selfpaced": true, 
    "topic_name": [
        "Business"
    ], 
    "description": "<p>The<strong> Hidden Markov Model </strong>or<strong class=\"redactor-inline-converted\"> HMM</strong> is all about learning sequences.</p>\n\n<p>A lot of the data that would be very useful for us to model is in sequences. <strong class=\"redactor-inline-converted\">Stock prices</strong> are sequences of prices. Language is a sequence of words. <strong class=\"redactor-inline-converted\">Credit scoring</strong> involves sequences of borrowing and repaying money, and we can use those sequences to predict whether or not you’re going to default. In short, sequences are everywhere, and being able to analyze them is an important skill in your <strong class=\"redactor-inline-converted\">data science</strong> toolbox.</p>\n\n\n\n\n\n\n\n\n\n<p>The easiest way to appreciate the kind of information you get from a sequence is to consider what you are reading right now. If I had written the previous sentence backwards, it wouldn’t make much sense to you, even though it contained all the same words. So order is important.</p>\n\n\n\n\n\n\n\n\n\n<p>While the current fad in <strong class=\"redactor-inline-converted\">deep learning </strong>is to use <strong class=\"redactor-inline-converted\">recurrent neural networks</strong> to model sequences, I want to first introduce you guys to a machine learning algorithm that has been around for several decades now - the Hidden Markov Model.</p>\n\n\n\n\n\n\n\n\n\n<p>This course follows directly from my first course in <strong class=\"redactor-inline-converted\">Unsupervised Machine Learning for Cluster Analysis</strong>, where you learned how to measure the <strong class=\"redactor-inline-converted\">probability distribution</strong> of a <strong class=\"redactor-inline-converted\">random variable</strong>. In this course, you’ll learn to measure the probability distribution of a sequence of random variables. </p>\n\n\n\n\n\n\n\n\n\n<p>You guys know how much I love <strong class=\"redactor-inline-converted\">deep learning</strong>, so there is a little twist in this course. We’ve already covered <strong class=\"redactor-inline-converted\">gradient descent</strong> and you know how central it is for solving deep learning problems. I claimed that gradient descent could be used to optimize any objective function. In this course I will show you how you can use gradient descent to solve for the optimal parameters of an HMM, as an alternative to the popular <strong class=\"redactor-inline-converted\">expectation-maximization</strong> algorithm.</p>\n\n\n\n\n\n\n\n\n\n<p>We’re going to do it in Theano, which is a popular library for deep learning. This is also going to teach you how to work with sequences in Theano, which will be very useful when we cover <strong class=\"redactor-inline-converted\">recurrent neural networks</strong> and <strong class=\"redactor-inline-converted\">LSTMs</strong>.</p>\n\n\n\n\n\n\n\n\n\n<p>This course is also going to go through the many practical applications of Markov models and hidden Markov models. We’re going to look at a model of sickness and health, and calculate how to predict how long you’ll stay sick, if you get sick. We’re going to talk about how Markov models can be used to analyze how people interact with your website, and fix problem areas like high <strong class=\"redactor-inline-converted\">bounce rate</strong>, which could be affecting your <strong class=\"redactor-inline-converted\">SEO</strong>. We’ll build language models that can be used to identify a writer and even generate text - imagine a machine doing your writing for you.</p>\n\n\n\n\n\n\n\n<p>We’ll look at what is possibly the most recent and prolific application of Markov models - <strong class=\"redactor-inline-converted\">Google’s PageRank</strong> algorithm. And finally we’ll discuss even more practical applications of Markov models, including generating images, <strong class=\"redactor-inline-converted\">smartphone</strong> <strong class=\"redactor-inline-converted\">autosuggestions</strong>, and using HMMs to answer one of the most fundamental questions in <strong class=\"redactor-inline-converted\">biology</strong> - how is <strong class=\"redactor-inline-converted\">DNA</strong>, the code of life, translated into physical or behavioral attributes of an organism?</p>\n\n\n\n\n\n<p>All of the materials of this course can be downloaded and installed for FREE. We will do most of our work in <strong class=\"redactor-inline-converted\">Numpy</strong> and <strong class=\"redactor-inline-converted\">Matplotlib</strong>, along with a little bit of <strong class=\"redactor-inline-converted\">Theano</strong>. I am always available to answer your questions and help you along your data science journey.</p>\n\n\n\n\n\n<p>See you in class!</p>\n\n\n\n<p><br></p><p>NOTES:</p><p>All the code for this course can be downloaded from my github: /lazyprogrammer/machine_learning_examples</p>\n\n<p>In the directory: hmm_class</p>\n\n<p>Make sure you always \"git pull\" so you have the latest version!</p>\n\n<p>HARD PREREQUISITES / KNOWLEDGE YOU ARE ASSUMED TO HAVE:</p>\n\n<ul><li>calculus</li><li>linear algebra</li><li>probability</li><li>Be comfortable with the multivariate Gaussian distribution</li><li>Python coding: if/else, loops, lists, dicts, sets</li><li>Numpy coding: matrix and vector operations, loading a CSV file</li></ul>", 
    "end_date": null, 
    "title": "Unsupervised Machine Learning Hidden Markov Models in Python", 
    "price": "50.00", 
    "instructors": "Justin C", 
    "commitment": "4 hours", 
    "cover_url": "https://udemy-images.udemy.com/course/750x422/872834_f01d.jpg", 
    "course_url": "https://www.udemy.com/unsupervised-machine-learning-hidden-markov-models-in-python/", 
    "currency": "USD", 
    "subject_name": [
        "Data & Analytics"
    ], 
    "duration": null, 
    "language_name": [
        "English"
    ], 
    "provider_name": [
        "udemy"
    ], 
    "start_date": "2016-06-08T22:20:20Z"
}
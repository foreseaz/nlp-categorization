{
    "selfpaced": true, 
    "topic_name": [
        "Development"
    ], 
    "description": "<p>  \t<strong style=\"\">Build your essential knowledge with this hands-on, introductory course on the Java parallel computation using the popular Hadoop framework:</strong>  </p>  <p>  \t- Getting Started with Hadoop  </p>  <p>  \t- HDFS working mechanism  </p>  <p>  \t- MapReduce working mecahnism  </p>  <p>  \t- An anatomy of the Hadoop cluster  </p>  <p>  \t- Hadoop VM in pseudo-distributed mode  </p>  <p>  \t- Hadoop VM in distributed mode  </p>  <p>  \t- Elaborated examples in using MapReduce  </p>  <p>  \t<strong style=\"\">Learn the Widely-Used Hadoop Framework</strong>  </p>  <p>  \tApache Hadoop is an open-source software framework for storage and large-scale processing of data-sets on clusters of commodity hardware. Hadoop is an Apache top-level project being built and used by a global community of contributors and users. It is licensed under the Apache License 2.0.  </p>  <p>  \tAll the modules in Hadoop are designed with a fundamental assumption that hardware failures (of individual machines, or racks of machines) are common and thus should be automatically handled in software by the framework. Apache Hadoop&#039;s MapReduce and HDFS components originally derived respectively from Google&#039;s MapReduce and Google File System (GFS) papers.  </p>  <p>  \t<strong style=\"\">Who are using Hadoop for data-driven applications?</strong>  </p>  <p>  \tYou will be surprised to know that many companies have adopted to use Hadoop already. Companies like Alibaba, Ebay, Facebook, LinkedIn, Yahoo! is using this proven technology to harvest its data, discover insights and empower their different applications!  </p>  <p>  \t<strong style=\"\">Contents and Overview</strong>  </p>  <p>  \tAs a software developer, you might have encountered the situation that your program takes too much time to run against large amount of data. If you are looking for a way to scale out your data processing, this is the course designed for you. This course is designed to build your knowledge and use of Hadoop framework through modules covering the following:  </p>  <p>  \t- Background about parallel computation  </p>  <p>  \t- Limitations of parallel computation before Hadoop  </p>  <p>  \t- Problems solved by Hadoop  </p>  <p>  \t- Core projects under Hadoop - HDFS and MapReduce  </p>  <p>  \t- How HDFS works  </p>  <p>  \t- How MapReduce works  </p>  <p>  \t- How a cluster works  </p>  <p>  \t- How to leverage the VM for Hadoop learning and testing  </p>  <p>  \t- How the starter program works  </p>  <p>  \t- How the data sorting works  </p>  <p>  \t- How the pattern searching  </p>  <p>  \t- How the word co-occurrence  </p>  <p>  \t- How the inverted index works  </p>  <p>  \t- How the data aggregation works  </p>  <p>  \t- All the examples are blended with full source code and elaborations  </p>  <p>  \t<strong style=\"\">Come and join us! With this structured course, you can learn this prevalent technology in handling Big Data.</strong>  </p>", 
    "end_date": null, 
    "title": "Java Parallel Computation on Hadoop", 
    "price": 0, 
    "instructors": "Ivan Ng", 
    "commitment": "3 hours", 
    "cover_url": "https://udemy-images.udemy.com/course/750x422/183012_2796_3.jpg", 
    "course_url": "https://www.udemy.com/java-parallel-computation-on-hadoop-in-4-hours/", 
    "subject_name": [
        "Databases"
    ], 
    "duration": null, 
    "language_name": [
        "English"
    ], 
    "provider_name": [
        "udemy"
    ], 
    "start_date": "2014-03-15T10:14:52Z"
}
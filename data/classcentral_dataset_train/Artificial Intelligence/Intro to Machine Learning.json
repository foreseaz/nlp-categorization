{"selfpaced": true, "topic_name": ["Artificial Intelligence"], "description": "\n\n                    \n                    \n                    Machine Learning is a first-class ticket to the most exciting careers in data analysis today. As data sources proliferate along with the computing power to process them, going straight to the data is one of the most straightforward ways to quickly gain insights and make predictions.  \n\nMachine learning brings together computer science and statistics to harness that predictive power. It\u2019s a must-have skill for all aspiring data analysts and data scientists, or anyone else who wants to wrestle all that raw data into refined trends and predictions.\n\nThis is a class that will teach you the end-to-end process of investigating data through a machine learning lens. It will teach you how to extract and identify useful features that best represent your data, a few of the most important machine learning algorithms, and how to evaluate the performance of your machine learning algorithms.\n\nThis course is also a part of our Data Analyst Nanodegree.Why Take This Course?In this course, you\u2019ll learn by doing! We\u2019ll bring machine learning to life by showing you fascinating use cases and tackling interesting real-world problems like self-driving cars. For your final project you\u2019ll mine the email inboxes and financial data of Enron to identify persons of interest in one of the greatest corporate fraud cases in American history.\n\nWhen you finish this introductory course, you\u2019ll be able to analyze data using machine learning techniques, and you\u2019ll also be prepared to take our Data Analyst Nanodegree. We\u2019ll get you started on your machine learning journey by teaching you how to use helpful tools, such as pre-written algorithms and libraries, to answer interesting questions.\n\n                                            Syllabus\n                        You\u2019ll learn how to start with a question and/or a dataset, and use machine learning to turn them into insights. \n\n###Lessons 1-4: Supervised Classification\n\n**Naive Bayes:** We jump in headfirst, learning perhaps the world\u2019s greatest algorithm for classifying text.\n\n**Support Vector Machines (SVMs):** One of the top 10 algorithms in machine learning, and a must-try for many classification tasks.  What makes it special?  The ability to generate new features independently and on the fly.\n\n**Decision Trees:** Extremely straightforward, often just as accurate as an SVM but (usually) way faster.  The launch point for more sophisticated methods, like random forests and boosting.\n\n###Lesson 5: Datasets and Questions\nBehind any great machine learning project is a great dataset that the algorithm can learn from.  We were inspired by a treasure trove of email and financial data from the Enron corporation, which would normally be strictly confidential but became public when the company went bankrupt in a blizzard of fraud.  Follow our lead as we wrestle this dataset into a machine-learning-ready format, in anticipation of trying to predict cases of fraud.\n\n###Lesson 6 and 7: Regressions and Outliers\nRegressions are some of the most widely used machine learning algorithms, and rightly share prominence with classification.  What\u2019s a fast way to make mistakes in regression, though?  Have troublesome outliers in your data.  We\u2019ll tackle how to identify and clean away those pesky data points.\n\n###Lesson 8: Unsupervised Learning\n\n**K-Means Clustering:** The flagship algorithm when you don\u2019t have labeled data to work with, and a quick method for pattern-searching when approaching a dataset for the first time.\n\n###Lessons 9-12: Features, Features, Features\n\n**Feature Creation:** Taking your human intuition about the world and turning it into data that a computer can use.\n\n**Feature Selection:** Einstein said it best: make everything as simple as possible, and no simpler.  In this case, that means identifying the most important features of your data.\n\n**Principal Component Analysis:** A more sophisticated take on feature selection, and one of the crown jewels of unsupervised learning.\n\n**Feature Scaling:** Simple tricks for making sure your data and your algorithm play nicely together.\nLearning from Text: More information is in text than any other format, and there are some effective but simple tools for extracting that information.\n\n###Lessons 13-14: Validation and Evaluation\n\n**Training/testing data split:** How do you know that what you\u2019re doing is working?  You don\u2019t, unless you validate.  The train-test split is simple to do, and the gold standard for understanding your results.\n\n**Cross-validation:** Take the training/testing split and put it on steroids.  Validate your machine learning results like a pro.\n\n**Precision, recall, and F1 score:**  After all this data-driven work, quantify your results with metrics tailored to what is most important to you.\n \n###Lesson 15: Wrapping it all Up\nWe take a step back and review what we\u2019ve learned, and how it all fits together.  \n\n###Projects\n\nMini-project at the end of each lesson\n\n**Final project:** searching for signs of corporate fraud in Enron data\n                                    ", "end_date": "2015-02-06T00:00:00Z", "title": "Intro to Machine Learning", "price": 0, "instructors": "", "institution_name": ["Stanford University"], "commitment": "6 hours", "subject_name": ["Computer Science"], "course_url": "https://www.udacity.com/course/intro-to-machine-learning--ud120?utm_medium=referral&utm_campaign=api", "duration": "10 weeks", "language_name": ["English"], "provider_name": ["Udacity"], "start_date": "2014-11-28T00:00:00Z"}
{
    "selfpaced": false, 
    "topic_name": [
        "Artificial Intelligence"
    ], 
    "description": "\n\n                    \n                    \n                    Не так давно получил распространение термин «большие данные», обозначивший новую прикладную область — поиск способов автоматического быстрого анализа огромных объёмов разнородной информации. Наука о больших данных ещё только оформляется, но уже сейчас она очень востребована — и в будущем будет востребована только больше.\nС её помощью можно решать невероятные задачи: оценивать состояние печени по кардиограмме, предсказывать зарплату по описанию вакансии, предлагать пользователю музыку на основании его анкеты в интернете.\n\nБольшими данными может оказаться что угодно: результаты научных экспериментов, логи банковских транзакций, метеорологические наблюдения, профили в социальных сетях — словом, всё, что может быть полезно проанализировать.\nСамым перспективным подходом к анализу больших данных считается применение машинного обучения — набора методов, благодаря которым компьютер может находить в массивах изначально неизвестные взаимосвязи и закономерности.\n\nНа факультете компьютерных наук ВШЭ и в Школе анализа данных есть люди, активно использующие машинное обучение и разрабатывающие новые подходы к нему. Именно они — преподаватели этого курса.\n\nВы изучите основные типы задач, решаемых с помощью машинного обучения — в основном речь пойдёт о классификации, регрессии и кластеризации. Узнаете об основных методах машинного обучения и их особенностях, научитесь оценивать качество моделей — и решать, подходит ли модель для решения конкретной задачи. Наконец, познакомитесь с современными библиотеками, в которых реализованы обсуждаемые модели и методы оценки их качества. Для работы мы будем использовать реальные данные из реальных задач.\n\nКраткая программа курса:\nНеделя 1. Введение. Примеры задач. Логические методы: решающие деревья и решающие леса.\nНеделя 2. Метрические методы классификации. Линейные методы, стохастический градиент.\nНеделя 3. Метод опорных векторов (SVM). Логистическая регрессия. Метрики качества классификации.\nНеделя 4. Линейная регрессия. Понижение размерности, метод главных компонент.\nНеделя 5. Композиции алгоритмов, градиентный бустинг. Нейронные сети.\nНеделя 6. Кластеризация и визуализация. Частичное обучение.\nНеделя 7. Прикладные задачи анализа данных: постановки и методы решения.\n\nСлушателю нужно знать об основных понятиях математики: функциях, производных, векторах, матрицах. Для выполнения практических заданий потребуются базовые навыки программирования. Очень желательно знать Python. Задания рассчитаны на использование этого языка и его библиотек numpy, pandas и scikit-learn.\n\nЧтобы успешно завершить курс, нужно набрать проходную сумму баллов за тесты и практические задания, а также выполнить финальный проект, посвящённый решению прикладной задачи анализа данных.\n\nМы уверены, что этот курс будет полезен каждому, кто хочет постичь искусство предсказательного моделирования и освоить интеллектуальный анализ данных.\n\n                                            Syllabus\n                        Знакомство с анализом данных и машинным обучениемДобро пожаловать! В первом модуле курса мы расскажем о задачах, которые решает машинное обучение, определим базовый набор понятий и введем необходимые обозначения. Также мы расскажем про основные библиотеки языка Python для работы с данными (NumPy, Pandas, Scikit-Learn), которые понадобятся для выполнения практических заданий на протяжении всего курса.Логические методы классификацииЛогические методы делают классификацию объектов на основе простых правил, благодаря чему являются интерпретируемыми и легкими в реализации. При объединении в композицию логические модели позволяют решать многие задачи с высоким качеством. В этом модуле мы изучим основной класс логических алгоритмов — решающие деревья. Также мы поговорим про объединение деревьев в композицию, называемую случайным лесом.Метрические методы классификацииМетрические методы проводят классификацию на основе сходства, благодаря чему могут работать на данных со сложной структурой — главное, чтобы между объектами можно было измерить расстояние. Мы изучим метод k ближайших соседей, а также способ его обобщения на задачи регрессии с помощью ядерного сглаживания.Линейные методы классификацииЛинейные модели — один из наиболее изученных классов алгоритмов в машинном обучении. Они легко масштабируются и широко применяются для работы с большими данными. В этом модуле мы изучим метод стохастического градиента для настойки линейных классификаторов, познакомимся с регуляризацией и обсудим некоторые тонкости работы с линейными методами.Метод опорных векторов и логистическая регрессияЛинейные методы имеют несколько очень важных подвидов, о которых пойдет речь в этом модуле. Метод опорных векторов максимизирует отступы объектов, что тесно связано с минимизацией вероятности переобучения.  При этом он позволяет очень легко перейти к построению нелинейной разделяющей поверхности благодаря ядровому переходу. Логистическая регрессия позволяет оценивать вероятности принадлежености классам, что оказывается полезным во многих прикладных задачах.Метрики качества классификацииВ машинном обучении существует большое количество метрик качества, каждая из которых имеет свою прикладную интерпретацию и направлена на измерение конкретного свойства решения. В этом модуле мы обсудим, какие бывают метрики качества бинарной и многоклассовой классификации, а также рассмотрим способы сведения многоклассовых задач к двухклассовым.Линейная регрессияВ этом модуле мы изучим линейные модели для регрессии и обсудим их связь с сингулярным разложением матрицы \"объекты-признаки\".Понижение размерности и метод главных компонентВ прикладных задачах часто возникает потребность в уменьшении количества признаков — например, для ускорения работы моделей. В этом модуле мы обсудим подходы к отбору признаков, а также изучим метод главных компонент, один из самых популярных методов понижения размерности.Композиции алгоритмовОбъединение большого числа моделей в композицию может значительно улучшить итоговое качество за счет того, что отдельные модели будут исправлять ошибки друг друга. В этом модуле мы обсудим основные понятия и постановки задач, связанные с композициями, и обсудим один из наиболее распространенных способов их построения — градиентный бустинг.Нейронные сетиНейронные сети позволяют находить сложные нелинейные разделяющие поверхности, благодаря чему широко используются в таких трудных задачах, как распознавание изображений и речи. В этом модуле мы изучим многослойные нейронные сети и их настройку с помощью метода обратного распространения ошибки. Также мы поговорим о глубоких нейросетях, их архитектурах и особенностях.Кластеризация и визуализацияЭтот модуль посвящен новому классу задач в машинном обучении — обучению без учителя. Под этим понимаются ситуации, в которых нужно найти структуру в данных или произвести их \"разведку\". В этом  модуле мы обсудим две таких задачи: кластеризацию (поиск групп схожих объектов) и визуализацию (отображение объектов в двух- или трехмерное пространство).Частичное обучениеПод частичным обучение понимается задача, находящаяся между обучением с учителем и кластеризацией: дана выборка, в которой значение целевой переменной известно лишь для части объектов. Такие ситуации встречаются, когда разметка объектов является дорогой операцией, но при этом достаточно дешево можно подсчитать признаки для объектов. В этом модуле мы обсудим отличия частичного обучения от рассмотренных ранее постановок, и разберем несколько подходов к решению.Машинное обучение в прикладных задачахВ этом модуле мы подведем итоги курса, вспомним основные этапы решения задачи анализа данных. Также мы разберем несколько задач из прикладных областей, чтобы подготовиться к выполнению финального проекта.\n                                    ", 
    "end_date": "2016-08-01T00:00:00Z", 
    "title": "Введение в машинное обучение", 
    "price": 0, 
    "instructors": "Константин Вячеславович Воронцов", 
    "institution_name": [
        "Higher School of Economics"
    ], 
    "commitment": "", 
    "subject_name": [
        "Computer Science"
    ], 
    "course_url": "https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie", 
    "duration": "7 weeks", 
    "language_name": [
        "Others"
    ], 
    "provider_name": [
        "Coursera"
    ], 
    "start_date": "2016-06-13T00:00:00Z"
}
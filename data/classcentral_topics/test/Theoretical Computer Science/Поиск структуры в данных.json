{
    "selfpaced": false, 
    "topic_name": [
        "Theoretical Computer Science"
    ], 
    "description": "\n\n                    \n                    \n                    В машинном обучении встречаются задачи, где нужно изучить структуру данных, найти в них скрытые взаимосвязи и закономерности. Например, нам может понадобиться описать каждого клиента банка с помощью меньшего количества переменных — для этого можно использовать методы понижения размерности, основанные на матричных разложениях. Такие методы пытаются сформировать новые признаки на основе старых, сохранив как можно больше информации в данных. Другим примером может служить задача тематического моделирования, в которой для набора текстов нужно построить модель, объясняющую процесс формирования этих текстов из небольшого количества тем.\n\nТакие задачи назвают обучением без учителя. В отличие от обучения с учителем, в них не предполагают восстановление зависимости между объектами и целевой переменной. \n\nИз этого курса вы узнаете об алгоритмах кластеризации данных, с помощью которых, например, можно искать группы схожих клиентов мобильного оператора. Вы научитесь строить матричные разложения и решать задачу тематического моделирования, понижать размерность данных, искать аномалии и визуализировать многомерные данные.\n\n                                            Syllabus\n                        КластеризацияДобро пожаловать на курс \"Поиск структуры в данных\"! В этом курсе вы узнаете про задачи машинного обучения, в которых требуется не предсказать целевую переменную, а найти некоторые внутренние закономерности в данных — например, сгруппировать объекты по схожести, или определить наиболее важные признаки. В первом модуле мы изучим задачу кластеризации, направленную на поиск групп близких объектов. Вы узнаете про основные подходы к её решению, а также узнаете, как можно выбрать хороший алгоритм кластеризации, не имея правильных ответов.Понижение размерности и матричные разложенияВ предыдущем модуле мы обсуждали, как кластеризовать объекты, а в этом модуле займёмся признаками. Нередко возникают ситуации, в которых далеко не все признаки нужны для решения задачи — или же нужны все, но при этом их слишком много. В этом случае нужно перейти в новое признаковое пространство меньшей размерности. Для этого можно либо отбирать наиболее важные признаки, либо порождать новые на основе исходных — мы обсудим оба подхода. В частности, мы разберёмся с методом главных компонент, который используется в самых разных задачах машинного обучения. Затем мы перейдём к матричным разложениям — мы изучим несколько методов, позволяющих получить приближение исходной матрицы в виде произведения нескольких матриц меньшей размерности. Такая аппроксимация часто используется в задачах машинного обучения, например, для понижения размерности данных, восстановления пропущенных значений в матрицах и построения рекомендательных систем.Визуализация и поиск аномалийДобро пожаловать на третью неделю курса! В ней мы обсудим две задачи: обнаружение аномалий и визуализация данных. Обнаружение аномалий направлено на поиск объектов, которые являются особенными в некотором смысле. Например, это могут объекты с такими значениями признаков, которые далеки от имеющихся в обучающей выборке — вполне ожидаемо, что на таких объектах модель выдаст очень плохие прогнозы. Вы узнаете, как можно формально дать определение аномалий и с помощью каких методов можно решать задачу их поиска. Вторая задача, о которой мы поговорим — это визуализация, то есть отображение многомерной выборки в пространство размерности два или три. В теории визуализация близка к понижению размерности — но за счёт того, что нам нужно найти всего два или три признака, можно использовать очень сложные нелинейные методы.Тематическое моделированиеЛюди уже много веков сохраняют свои знания в виде книг, а крупнейшая на сегодняшний день коллекция информации — Интернет — состоит из огромного количества текстов. Тексты, по сути, являются наиболее популярным видом данных, и поэтому очень важно уметь искать в них закономерности. Тематическое моделирование — это способ семантического анализа коллекции текстовых документов. Тематическая модель позволяет для каждого документа найти темы, которые его описывают, и кроме того показывает, какие слова характеризуют ту или иную тему. Другими словами, мы находим более компактное представление большого набора текстов в виде нескольких тем. С математической точки зрения тематическая модель — это еще один вид матричного разложения, где в качестве исходной матрицы выступает матрица частот слов в документах. На четвертой неделе мы поговорим о том, где применяют тематические модели, какие они бывают, как их строить и как оценивать. \n                                    ", 
    "end_date": "2016-06-20T00:00:00Z", 
    "title": "Поиск структуры в данных", 
    "price": 0, 
    "instructors": "Евгений Соколов, Эмели Драль, Виктор Кантор and Евгений Рябенко", 
    "institution_name": [
        "Moscow Institute of Physics and Technology"
    ], 
    "commitment": "", 
    "subject_name": [
        "Computer Science"
    ], 
    "course_url": "https://www.coursera.org/learn/unsupervised-learning", 
    "duration": "4 weeks", 
    "language_name": [
        "Others"
    ], 
    "provider_name": [
        "Coursera"
    ], 
    "start_date": "2016-05-23T00:00:00Z"
}